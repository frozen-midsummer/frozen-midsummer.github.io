---
lang: zh-CN
title: 海量数据问题
description: 海量数据问题
sidebar: heading
---

# 方法总述

处理海量数据问题，无非就是：

1. 分而治之/hash映射 + hash统计 + 堆/快速/归并排序；
2. Bloom filter/Bitmap；
3. Trie树/数据库/倒排索引；
4. 外排序；
5. 分布式处理之hadoop/mapreduce。

---

### 布隆过滤器

> 适用范围

​		==检索元素是否在给定大集合中的数据结构==，这种数据结构是高效且性能很好的，但缺点是具有一定的错误识别率和删除难度。并且，理论情况下，添加到集合中的元素越多，误报的可能性就越大。

**使用场景：**

1. **判断给定数据是否存在**：
   - 比如判断一个数字是否存在于包含大量数字的数字集中（数字集很大，5 亿以上！）
   - 防止缓存穿透（判断请求的数据是否有效避免直接绕过缓存请求数据库）
   - 邮箱的垃圾邮件过滤、黑名单功能等等。
2. **去重**：比如爬给定网址的时候对已经爬取过的 URL 去重。

> 基本原理及要点

**当一个元素加入布隆过滤器中的时候，会进行如下操作：**

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

结论：

​	因为不同的字符串可能哈希出来的位置相同，这种情况我们可以适当增加位数组大小或者调整我们的哈希函数。也就是说，**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

> 实现

1. [手动实现布隆过滤器（Java）](https://javaguide.cn/cs-basics/data-structure/bloom-filter/#%E9%80%9A%E8%BF%87-java-%E7%BC%96%E7%A8%8B%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8)

2. Google开源的Guava中自带的布隆过滤器

   ```java
   //首先引入依赖
   <dependency>
       <groupId>com.google.guava</groupId>
       <artifactId>guava</artifactId>
       <version>28.0-jre</version>
   </dependency>
   
   // 创建了一个最多存放最多 1500 个整数的布隆过滤器，并且我们可以容忍误判的概率为0.01
   BloomFilter<Integer> filter = BloomFilter.create(
       Funnels.integerFunnel(),
       1500,
       0.01);
   // 判断指定元素是否存在
   System.out.println(filter.mightContain(1));
   System.out.println(filter.mightContain(2));
   // 将元素添加进布隆过滤器
   filter.put(1);
   filter.put(2);
   System.out.println(filter.mightContain(1));
   System.out.println(filter.mightContain(2));
   //当 mightContain() 方法返回 true 时，我们可以 99％确定该元素在过滤器中，当过滤器返回 false 时，我们可以 100％确定该元素不存在于过滤器中。
   ```

3. Redis中的布隆过滤器：Redis v4.0 之后有了 Module（模块/插件） 功能，Redis Modules 让 Redis 可以使用外部模块扩展其功能 。布隆过滤器就是其中的 Module。

---

### BitMap

**适用范围**

可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下

**基本原理及要点**

使用bit数组来表示某些元素是否存在，比如8位电话号码

**扩展**

bloom filter可以看做是对bit-map的扩展

**问题实例**

1. 已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。

   8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。

2. 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。

   将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map。

### Hash

**适用范围**

快速查找，删除的基本数据结构，通常需要总数据量可以放入内存

**基本原理及要点**

hash函数选择，针对字符串，整数，排列，具体相应的hash方法。

碰撞处理，一种是open hashing，也称为拉链法；另一种就是closed hashing，也称开地址法，opened addressing。

 **扩展**

d-left hashing中的d是多个的意思，我们先简化这个问题，看一看2-left hashing。2-left hashing指的是将一个哈希表分成长度相等的两半，分别叫做T1和T2，给T1和T2分别配备一个哈希函数，h1和h2。在存储一个新的key时，同时用两个哈希函数进行计算，得出两个地址h1[key]和h2[key]。这时需要检查T1中的h1[key]位置和T2中的h2[key]位置，哪一个位置已经存储的（有碰撞的）key比较多，然后将新key存储在负载少的位置。如果两边一样多，比如两个位置都为空或者都存储了一个key，就把新key存储在左边的T1子表中，2-left也由此而来。在查找一个key时，必须进行两次hash，同时查找两个位置。

**问题实例**

1. **海量日志数据，提取出某日访问百度次数最多的那个IP**。

   IP的数目还是有限的，最多2^32个，所以可以考虑使用hash将ip直接存入内存，然后进行统计。

### 堆

**适用范围**

海量数据前n大，并且n比较小，堆可以放入内存

**基本原理及要点**

最大堆求前n小，最小堆求前n大。

方法，比如求前n小，我们比较当前元素与最大堆里的最大元素，如果它小于最大元素，则应该替换那个最大元素。这样最后得到的n个元素就是最小的n个。适合[**大数据**](http://lib.csdn.net/base/hadoop)量，求前n小，n的大小比较小的情况，这样可以扫描一遍即可得到所有的前n元素，效率很高。

**扩展**

双堆，一个最大堆与一个最小堆结合，可以用来维护中位数。

**问题实例**

1. 100w个数中找最大的前100个数。

   用一个100个元素大小的最小堆即可。

### 双层桶划分----其实本质上就是【分而治之】的思想，重在“分”的技巧上！

**适用范围**

第k大，中位数，不重复或重复的数字
**基本原理及要点**

因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。可以通过多次缩小，双层只是一个例子。
**问题实例**

1. 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。

   有点像鸽巢原理，整数个数为2^32，也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。

2. 5亿个int找它们的中位数
   首先我们将 int 划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。

   然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

　　实际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成2^24个区域，然后确定区域的第几大数，在将该区域分成2^20个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有2^20，就可以直接利用direct addr table进行统计了。

### 数据库索引

**适用范围**

大数据量的增删改查

**基本原理及要点**

利用数据的设计实现方法，对海量数据的增删改查进行处理。

### 倒排索引

**适用范围**

搜索引擎，关键字查询

**基本原理及要点**

一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的**存储位置的映射**。

以英文为例，下面是要被索引的文本：
   T0 = "it is what it is"
   T1 = "what is it"
   T2 = "it is a banana"

我们就能得到下面的反向文件索引：

  "a":   {2}
   "banana": {2}
   "is":   {0, 1, 2}
   "it":   {0, 1, 2}
   "what":  {0, 1}

检索的条件"what","is"和"it"将对应集合的交集。

正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档，很容易看到这个反向的关系。

**扩展**

文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索。

### 外排序

**适用范围**

大数据的排序，去重

**基本原理及要点**

外排序的归并方法，置换选择败者树原理，最优归并树

**问题实例**

1. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词。

   这个数据具有很明显的特点，词的大小为16个字节，但是内存只有1m做hash有些不够，所以可以用来排序。内存可以当输入缓冲区使用。

### trie树

**适用范围**

数据量大，重复多，但是数据种类小可以放入内存

**基本原理及要点**

实现方式，节点孩子的表示方式

**扩展**

压缩实现。

**问题实例**

1. 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。
2. 1000万字符串，其中有些是相同的(重复)，需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？
3. 寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。

### 分布式处理 mapreduce

**适用范围**

数据量大，但是数据种类小可以放入内存

**基本原理及要点**

将数据交给不同的机器去处理，数据划分，结果归约。

**问题实例**

1. The canonical example application of MapReduce is a process to count the appearances of
    each different word in a set of documents:
2. 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。
3. 一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)？

 **经典问题分析**

上千万or亿数据（有重复），统计其中出现次数最多的前N个数据,分两种情况：可一次读入内存，不可一次读入。

**可用思路**：trie树+堆，数据库索引，划分子集分别统计，hash，分布式计算，近似统计，外排序

　　所谓的是否能一次读入内存，实际上应该指去除重复后的数据量。如果去重后数据可以放入内存，我们可以为数据建立字典，比如通过 map，hashmap，trie，然后直接进行统计即可。当然在更新每条数据的出现次数的时候，我们可以利用一个堆来维护出现次数最多的前N个数据，当然这样导致维护次数增加，不如完全统计后在求前N大效率高。

　　如果数据无法放入内存。一方面我们可以考虑上面的字典方法能否被改进以适应这种情形，可以做的改变就是将字典存放到硬盘上，而不是内存，这可以参考数据库的存储方法。

　　当然还有更好的方法，就是可以采用分布式计算，基本上就是map-reduce过程，首先可以根据数据值或者把数据hash(md5)后的值，将数据按照范围划分到不同的机子，最好可以让数据划分后可以一次读入内存，这样不同的机子负责处理各种的数值范围，实际上就是map。得到结果后，各个机子只需拿出各自的出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是reduce过程。

　　实际上可能想直接将数据均分到不同的机子上进行处理，这样是无法得到正确的解的。因为一个数据可能被均分到不同的机子上，而另一个则可能完全聚集到一个机子上，同时还可能存在具有相同数目的数据。比如我们要找出现次数最多的前100个，我们将1000万的数据分布到10台机器上，找到每台出现次数最多的前 100个，归并之后这样不能保证找到真正的第100个，因为比如出现次数最多的第100个可能有1万个，但是它被分到了10台机子，这样在每台上只有1千个，假设这些机子排名在1000个之前的那些都是单独分布在一台机子上的，比如有1001个，这样本来具有1万个的这个就会被淘汰，即使我们让每台机子选出出现次数最多的1000个再归并，仍然会出错，因为可能存在大量个数为1001个的发生聚集。因此不能将数据随便均分到不同机子上，而是要根据hash 后的值将它们映射到不同的机子上处理，让不同的机器处理一个数值范围。

# 密匙一、分而治之/hash映射 + hash统计 + 堆/快速/归并排序

## 1 海量日志数据，提取出某日访问百度次数最多的那个IP

首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。

或者如下阐述（雪域之鹰）：

**算法思想：分而治之+Hash**

1. IP地址最多有 2^32=4G 种取值情况，所以不能完全加载到内存中处理； 
2. **分而治之/Hash映射**：可以考虑采用“分而治之”的思想，按照 IP 地址的 Hash(IP)%1024 值，把海量 IP 日志分别存储到1024 个小文件中。这样，每个小文件最多包含 4MB 个IP地址； 
3. **hash统计**：对于每一个小文件，可以构建一个 IP 为 key，出现次数为 value 的 Hash map，同时记录当前出现次数最多的那个 IP 地址；
4. **堆/快速排序**：可以得到 1024 个小文件中的出现次数最多的 IP，再依据常规的排序算法得到总体上出现次数最多的 IP；

> 所以上面第2步可以保证同一个IP不会被散列到不同的小文件上

## 2 (百度)搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。

**百度面试题**

假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

**问题解析：**

要统计最热门查询，首先就是要统计每个查询出现的次数，然后根据统计结果，找出Top 10。所以我们可以基于这个思路分两步来设计该算法。即，此问题的解决分为以下两个步骤：

**第一步：查询统计**

维护一个Key 为Query 字串，Value 为该 Query 出现次数的 HashMap，统计每个 Query 字段出现的次数，最终我们在**O(N)**的时间复杂度内完成了对该海量数据的处理。

**第二步：找出Top 10**

借助**小根堆**，找出Top K，时间复杂度为N‘logK。

具体过程是，堆顶存放的是整个堆中最小的数，现在遍历N个数，把最先遍历到的k个数存放到最小堆中，并假设它们就是我们要找的最大的k个数，X1>X2...Xmin(堆顶)，而后遍历后续的N-K个数，一一与堆顶元素进行比较，如果遍历到的Xi大于堆顶元素Xmin，则把Xi放入堆中，而后更新整个堆，更新的时间复杂度为logK，如果Xi<Xmin，则不更新堆，整个过程的复杂度为O(K)+O((N-K)logK)=**O(NlogK)**。

所以，我们最终的时间复杂度是：**O（N） + N'\*O（logK）。**（N为1000万，N’为300万）

## 3 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。

1. **分而治之/hash映射**

   顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。

2. **hash统计**

   对每个小文件，采用trie树/hash_map等统计每个文件中出现的词以及相应的频率。

3. **堆/归并排序**

   取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。最后就是把这5000个文件进行归并（类似与归并排序）的过程了。

## 4 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。

**方案一**

1. **hash映射**

   顺序读取10个文件，按照hash(query)%10的结果将 query 写入到另外10 个文件（记为）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。

2. **hash统计**

   找一台内存在 2G 左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。注：hash_map(query,query_count)是用来统计每个query的出现次数，不是存储他们的值，出现一次，则count+1。

3. **堆/快速/归并排序**

   利用快速/堆/归并排序按照出现次数进行排序。将排序好的 query 和对应的query_cout输出到文件中。这样得到了10个排好序的文件（记为）。对这10个文件进行归并排序（内排序与外排序相结合）。

**方案二**

 一般 query 的总量是有限的，只是重复的次数比较多而已，可能对于所有的 query，一次性就可以加入到内存了。这样，我们就可以采用 trie 树/hash_map 等直接来统计每个 query 出现的次数，然后按出现次数做快速/堆/归并排序就可以了。

**方案三**

与方案1类似，但在做完 hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。

## 5 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

**方案一**

可以估计每个文件安的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。

1. **分而治之/Hash映射**

   遍历文件a，对每个 url 求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,...,a999）中。这样每个小文件的大约为 300M。

   遍历文件b，采取和a相同的方式将 url 分别存储到1000小文件（记为b0,b1,...,b999）。

   这样处理后，所有可能相同的 url 都在对应的小文件（a0vsb0,a1vsb1,...,a999vsb999）中，不对应的小文件不可能有相同的 url。然后我们只要求出1000对小文件中相同的 url 即可。

2. **Hash统计**

   求每对小文件中相同的 url 时，可以把其中一个小文件的 url 存储到 hash_set 中。然后遍历另一个小文件的每个 url，看其是否在刚才构建的 hash_set 中，如果是，那么就是共同的 url，存到文件里面就可以了。

**方案二**

如果允许有一定的错误率，可以使用**Bloom filter**，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。

## 6 怎么在海量数据中找出重复次数最多的一个？

只用2GB内存在20亿个整数中找到出现次数最多的数

1. **分而治之/Hash映射**

   把包含20亿个数的小文件用哈希函数分为16个小文件，根据哈希函数的性质，同一种数不可能被散列到不同的小文件上，同时每个小文件中不同的数一定不会大于2亿种，假设哈希函数足够优秀

2. **Hash统计**

   对每一个小文件用哈希表来统计其中每种数出现的次数，这样就得到了16个文件中各自出现次数最多的数，还有各自的次数统计

3. **堆/快速/归并排序**

   选出16个小文件各自的第一名中谁出现的次数最多即可

## 7 上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。

上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map/搜索二叉树/红黑树等来进行统计次数。然后就是取出前N个出现次数最多的数据了，可以用第2题提到的堆机制完成。

## 8 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。

这题是考虑时间效率。

1. 用 **trie树** 统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度）。*
2. 找出出现最频繁的前10个词，可以用堆来实现，前面的题中已经讲到了，时间复杂度是O(n*lg10)。*

所以总的时间复杂度，是O(n*le)与O(n*lg10)中较大的哪一个。







# 密匙二：Bloom filter/Bitmap



## 1 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。

 **方案1**

1. 采用**2-Bitmap**（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，用2个位置表示一个数出现的频率，整数 num 对应 Bitmap 中Bitmap[num\*2] 和 Bitmap[num\*2+1]两位，共需内存2^32 * 2 bit=1 GB内存，还可以接受。
2. 然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。

**方案二**

也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。

## 2 腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？

方案一：

直接读入内存大约需要16G（2^32^4byte），使用bigmap，大约需要512M（2^32bit）的内存，一个bit位（总共有40多亿个bit）代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。时间复杂度为O(n)

方案二：

因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；这里我们把40亿个数中的每一个用32位的二进制来表示。
假设这40亿个数开始放在一个文件中。然后将这40亿个数分成两类:      1.最高位为0    2.最高位为1  

并将这两类分别写入到两个文件中，其中一个文件中数的个数<=20亿，而另一个>=20亿（这相当于折半了）；与要查找的数的最高位比较并接着进入相应的文件再查找      

再然后把这个文件为又分成两类:    1.次最高位为0    2.次最高位为1    并将这两类分别写入到两个文件中，其中一个文件中数的个数<=10亿，而另一个>=10亿（这相当于折半了）；  与要查找的数的次最高位比较并接着进入相应的文件再查找。   .......   以此类推，就可以找到了,而且时间复杂度为O(logn)。









## 1. 给2000千万高考学生排序，要求要能根据分数找到该学生的排名？

千万别被2000千万这个数字唬住，理性的看一下题，“高考”这个词不知道你注意到了没？这是一个隐藏条件。你高考考了多少分？

总分多少？可能有的小伙伴已经反应过来了。高考750分，分数大小是固定的，那我们开一个750长度的数组，记录每个分数的的个数就可以了。

对，就是使用**桶排序**的算法，来进行排。

这一类题他虽然样子很吓人，但是仔细 发现他的范围很小，就抓住他这个范围小来做文章。

**时间复杂度：n      空间复杂度750**

## **2. 给2亿个不重复的正整数进行排序(范围0-2亿）？**

我们不能用一个int去装，可以用一位bit去装。

 **详解**：

1. **int = 4byte= 32bit**
2. 用一个int型的数组来存储数据，数组中每个元素都是Integer类型的，这样每个元素对应32位二进制位，让每一位二进制代表一个整数的话，这样，数组中的一个元素可以记录32个整数
3. 这样每个元素记录32个整数，则一共需要2亿/32 长度的数组
4. 先利用**x/32**找到数组下标，然后利用 **x%32** 找到他对应的整数中的位，令这一位为**1**

## **3. 给你一个超大的文件，找出出现频率最高的5个?**

这道题可能就没那个多的奇技淫巧了。

条件一个一个的增加，先是找出频率最高的5个，这个没有多余的话，肯定是根据频率最大堆排序。

那么一个超大文件，也就是说i我们内存没办法直接装下，可以将这个文件先分解（根据实际内存大小和文件大小判断，下边以5000份做例子），这时候我们把文件分成了5000份的小文件，然后我们为每个小文件构造一个数量为5的最大堆。其余的数字就可以清掉了。然后5000个小文件就行排序，这时候归并就要登场了。

我们通过归并然后对这5千个数据进行归并拿前5。这就找到了。

